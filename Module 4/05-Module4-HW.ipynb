{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "1) Load the breast_cancer dataset from skelarn (from sklearn.datasets import load_breast_cancer). Split the dataset into training and test datasets. Scale the dataset using minmaxscaler. Use KNeighborsClassifier classifier and report the score on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test dataset: 0.96\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the test dataset: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Repeat Step 1 using pipelines and report the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test dataset using pipeline: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),  # Step for scaling\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))  # KNN Classifier\n",
    "])\n",
    "\n",
    "# Step 4: Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Reporting the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the test dataset using pipeline: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Use the pipeline object from Step 2 and make a grid search on parameter of number of neighbor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'knn__n_neighbors': 6}\n",
      "Best cross-validated accuracy on training set: 0.96\n",
      "Test accuracy using best model: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with scaling and KNN\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Set up the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': np.arange(1, 21)  # Testing neighbors from 1 to 20\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Evaluate on the test set using the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Reporting results\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best cross-validated accuracy on training set: {best_score:.2f}\")\n",
    "print(f\"Test accuracy using best model: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)\tImport bike_day_raw.csv. Create a pipeline using ColumnTransformer, Scaling, and KNeighborsRegressor.\n",
    "\n",
    "- Use `from sklearn.neighbors import KNeighborsRegressor'\n",
    "- You need to split the data into X and y. \n",
    "- Check the data shape\n",
    "- Check the data types\n",
    "- Print the column names of the data frame\n",
    "- Create a scatterplot of each feature against the target variable\n",
    "- Create alist of features that are numeric and not numeric\n",
    "- Create a pipeline of imputer and standard scaler for the numeric features\n",
    "- Create a column transformer which uses the pipeline you created for numeric features and a onehotencoder for the non-numeric features\n",
    "- You can create your column transformer in different ways\n",
    "- Finally create a pipeline of column transformer and kNeighborsRegressor\n",
    "- Split your data into train and test datasets\n",
    "- Report the score on the test dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('bike_day_raw.csv')\n",
    "\n",
    "# Step 2: Split the data into features (X) and target (y)\n",
    "X = df.drop('target_variable', axis=1)  # Replace 'target_variable' with the actual name of the target column\n",
    "y = df['target_variable']\n",
    "\n",
    "# Step 3: Check the data shape\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "# Step 4: Check the data types\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n",
    "\n",
    "# Step 5: Print the column names of the DataFrame\n",
    "print(f\"Column names: {df.columns.tolist()}\")\n",
    "\n",
    "# Step 6: Create a scatterplot of each feature against the target variable\n",
    "for column in X.columns:\n",
    "    plt.scatter(X[column], y)\n",
    "    plt.title(f'Scatter plot of {column} vs target variable')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Target Variable')\n",
    "    plt.show()\n",
    "\n",
    "# Step 7: Create a list of features that are numeric and non-numeric\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_numeric_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(f\"Numeric features: {numeric_features}\")\n",
    "print(f\"Non-numeric features: {non_numeric_features}\")\n",
    "\n",
    "# Step 8: Create a pipeline of imputer and standard scaler for numeric features\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Step 9: Create a ColumnTransformer\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), non_numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 10: Create a pipeline of ColumnTransformer and KNeighborsRegressor\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', column_transformer),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Step 11: Split your data into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 12: Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 13: Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 14: Report the score on the test dataset\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 score on the test dataset: {score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
