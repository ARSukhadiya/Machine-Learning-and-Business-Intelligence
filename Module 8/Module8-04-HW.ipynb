{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e033a865-17a2-466a-8cde-a39cc6752deb",
    "_uuid": "c9e2806b423b6385a8d876545ab668324b6bb451"
   },
   "source": [
    "# Bank Marketing Data - A Decision Tree Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "459ad1ed-0e10-4dd1-a4f1-893ba5368175",
    "_uuid": "08bb7d7c3677ca15a39a3569cef5d2071e9b015e"
   },
   "source": [
    "## Aim:\n",
    "The aim of this attempt is to predict if the client will subscribe (yes/no) to a term deposit, by building a classification model using Decision Tree.\n",
    "### Step 1: Load the data\n",
    "- Load `bank.csv' data\n",
    "- Check the first five observations\n",
    "- Check if there are any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         job  marital  education default  balance housing loan  contact  \\\n",
      "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
      "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
      "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
      "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
      "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
      "\n",
      "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
      "0    5   may      1042         1     -1         0  unknown     yes  \n",
      "1    5   may      1467         1     -1         0  unknown     yes  \n",
      "2    5   may      1389         1     -1         0  unknown     yes  \n",
      "3    5   may       579         1     -1         0  unknown     yes  \n",
      "4    5   may       673         2     -1         0  unknown     yes  \n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "deposit      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'bank.csv'  # Make sure to replace with your actual path\n",
    "bank_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(bank_data.head())\n",
    "\n",
    "# Check for null values\n",
    "print(bank_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a727fd41-6e6e-424f-b65f-18c723b289a9",
    "_uuid": "de29791be07bcac0927cccfb6e858044d1b882ca"
   },
   "source": [
    "## Summay of data\n",
    "\n",
    "### Categorical Variables :\n",
    "**[1] job      :** admin,technician, services, management, retired, blue-collar, unemployed, entrepreneur,\n",
    "               housemaid, unknown, self-employed, student\n",
    "<br>**[2] marital  :** married, single, divorced\n",
    "<br>**[3] education:** secondary, tertiary, primary, unknown\n",
    "<br>**[4] default  :** yes, no\n",
    "<br>**[5] housing  :** yes, no\n",
    "<br>**[6] loan     :** yes, no \n",
    "<br>**[7] deposit  :** yes, no ** (Dependent Variable)**\n",
    "<br>**[8] contact  :** unknown, cellular, telephone\n",
    "<br>**[9] month    :** jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec\n",
    "<br>**[10] poutcome:** unknown, other, failure, success\n",
    "\n",
    "### Numerical Variables:\n",
    "**[1] age \n",
    "<br>[2] balance\n",
    "<br>[3] day\n",
    "<br>[4] duration\n",
    "<br>[5] campaign\n",
    "<br>[6] pdays\n",
    "<br>[7] previous **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Transformer\n",
    "- Create a trasnformer pipeline for numeric and categorical features. numerical features will be imputed and scaled. Categorical features will be imputed and encoded\n",
    "- Create a Column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the categorical and numerical columns\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', \n",
    "                        'contact', 'month', 'poutcome']\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Create the pipeline for numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with the mean\n",
    "    ('scaler', StandardScaler())  # Scale the features\n",
    "])\n",
    "\n",
    "# Create the pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent category\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode the categories\n",
    "])\n",
    "\n",
    "# Create the column transformer that applies the correct pipeline to each subset of features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),  # Apply numerical pipeline to numerical features\n",
    "        ('cat', categorical_pipeline, categorical_features)  # Apply categorical pipeline to categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Now you can use this `preprocessor` in a pipeline with a model, for example, a Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Classifier\n",
    "- Create a pipeline for the decision tree classifier as well as the transformer\n",
    "- Encode the target variable using `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.7847118542848611)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = bank_data.drop(columns=['deposit'])  # Features (all columns except 'deposit')\n",
    "y = bank_data['deposit']  # Target variable ('deposit')\n",
    "\n",
    "# Encode the target variable using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # Converts 'yes' -> 1, 'no' -> 0\n",
    "\n",
    "# Create the pipeline for the decision tree classifier along with the preprocessor\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Apply the preprocessing pipeline\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))  # Decision Tree classifier\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = model_pipeline.score(X_train, y_train)\n",
    "test_accuracy = model_pipeline.score(X_test, y_test)\n",
    "\n",
    "train_accuracy, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model\n",
    "- Create a pipeline for the decision tree classifier as well as the transformer\n",
    "- Encode the target variable using `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.7847118542848611\n"
     ]
    }
   ],
   "source": [
    "# Load the data (assuming data is loaded already as 'bank_data')\n",
    "X = bank_data.drop(columns=['deposit'])  # Features (all columns except 'deposit')\n",
    "y = bank_data['deposit']  # Target variable ('deposit')\n",
    "\n",
    "# Encode the target variable using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'yes' -> 1, 'no' -> 0\n",
    "\n",
    "# Identify the categorical and numerical columns\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', \n",
    "                        'contact', 'month', 'poutcome']\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Create the pipeline for numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with the mean\n",
    "    ('scaler', StandardScaler())  # Scale the features\n",
    "])\n",
    "\n",
    "# Create the pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent category\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode the categories\n",
    "])\n",
    "\n",
    "# Create the column transformer that applies the correct pipeline to each subset of features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),  # Apply numerical pipeline to numerical features\n",
    "        ('cat', categorical_pipeline, categorical_features)  # Apply categorical pipeline to categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a pipeline for the Decision Tree Classifier and Preprocessing steps\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Apply preprocessing to the data\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))  # Decision Tree classifier\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = model_pipeline.score(X_train, y_train)\n",
    "test_accuracy = model_pipeline.score(X_test, y_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training Accuracy: \", train_accuracy)\n",
    "print(\"Testing Accuracy: \", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
